{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "root = '' # full path to the root of the project (i.e. /media/MultiCaRe/)\n",
    "data_root = root + '' # folder containing the dataset (i.e. data/)\n",
    "images_folder = data_root + '' # folder containing the images (i.e. images/)\n",
    "table_path = data_root + '' # table with image labels (i.e. table.csv)\n",
    "save_path = root + '' # folder where to save files (i.e. models/)\n",
    "\n",
    "taxonomy_node = '' # name of the column of the table that will be used to train a submodel (i.e. image_type:radiology~anatomical_region:axial_region or image_type:endoscopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations, os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "h, w = 224, 224\n",
    "\n",
    "hyperparameters = {\n",
    "    'MODEL DESCRIPTION': taxonomy_node,\n",
    "    'BS': 16,\n",
    "    'EPOCHS': 30,\n",
    "    'IMG_SIZE': (h, w),      # (height, width)\n",
    "    'WD': 0.0,\n",
    "    'TRANSFORMS': [\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.VerticalFlip(p=0.5),\n",
    "        albumentations.Rotate(p=0.5),\n",
    "        albumentations.Sharpen(p=0.5),\n",
    "        albumentations.ColorJitter(brightness=0.3, contrast=0.5, saturation=0.5, hue=0.0, p=0.5),\n",
    "        albumentations.RGBShift(p=0.5),\n",
    "        albumentations.GaussianBlur(p=0.5),\n",
    "        albumentations.GaussNoise(p=0.5),\n",
    "        albumentations.RandomSizedCrop((int(0.75*h),h), h, w, p=1.0)\n",
    "        ],\n",
    "    'ARCH': 'convnext_tiny_in22k',\n",
    "    'LOSS_FUNC': 'LabelSmoothingCrossEntropyFlat',\n",
    "    'OPT_FUNC': 'Adam',\n",
    "    'USE_OVERSAMPLING': True,\n",
    "    'SEED': 18,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(table_path, column):\n",
    "    # Read data\n",
    "    data = pd.read_csv(table_path)\n",
    "    # Filter data    \n",
    "    data = data[data[column].notnull()]\n",
    "    # Get relevant info\n",
    "    image_files = data['file'].apply(lambda x: os.path.join(images_folder, x[:4], x[:5], x)).values\n",
    "    labels = data[column].values\n",
    "    groups = data['pmcid'].values\n",
    "    return image_files, labels, groups\n",
    "\n",
    "def create_df(image_files, labels, groups, n_splits=10, n_valid=2):\n",
    "    # Initiate dataframe\n",
    "    df = pd.DataFrame()\n",
    "    df['file_path'] = image_files\n",
    "    df['label'] = labels\n",
    "    df['groups'] = groups\n",
    "    df['fold'] = -1\n",
    "    # Make folds\n",
    "    cv = StratifiedGroupKFold(n_splits=n_splits)\n",
    "    for i, (train_idxs, valid_idxs) in enumerate(cv.split(image_files, labels, groups)):\n",
    "        df.loc[valid_idxs, ['fold']] = i\n",
    "    # Assign folds for validation\n",
    "    df['split'] = 'train'\n",
    "    for i in range (n_valid):\n",
    "        df.loc[df.fold == i, ['split']] = 'valid'\n",
    "    del df['fold']\n",
    "    df.split.value_counts()\n",
    "    # Add a binary column to the dataframe\n",
    "    df['is_valid'] = df.split == 'valid'\n",
    "    del df['split']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "image_files, labels, groups = get_data(table_path, hyperparameters['MODEL DESCRIPTION'])\n",
    "df = create_df(image_files, labels, groups)\n",
    "\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(hyperparameters['SEED'], True)\n",
    "\n",
    "class AlbumentationsTransform(DisplayedTransform):\n",
    "    '''\n",
    "    Class that allows the use of Albumentations transforms in FastAI.\n",
    "    '''\n",
    "    split_idx,order=0,2\n",
    "    def __init__(self, train_aug): store_attr()\n",
    "\n",
    "    def encodes(self, img: PILImage):\n",
    "        aug_img = self.train_aug(image=np.array(img))['image']\n",
    "        return PILImage.create(aug_img)\n",
    "\n",
    "# Determine the number of tasks\n",
    "n_tasks = len(df.label[0].split(', '))\n",
    "\n",
    "# Datablock\n",
    "block = DataBlock(\n",
    "    blocks=(ImageBlock,) + (CategoryBlock,) * n_tasks,\n",
    "    n_inp=1,\n",
    "    get_x=ColReader('file_path'),\n",
    "    get_y=[lambda x, i=i: x['label'].split(', ')[i] for i in range(n_tasks)],\n",
    "    splitter=ColSplitter(col='is_valid'),\n",
    "    item_tfms=[\n",
    "        Resize(hyperparameters['IMG_SIZE'], method='squish'), \n",
    "        AlbumentationsTransform(albumentations.Compose(hyperparameters['TRANSFORMS']))])\n",
    "\n",
    "# Dataloaders\n",
    "dls = block.dataloaders(df, bs=hyperparameters['BS'], shuffle=True)\n",
    "dls.rng.seed(hyperparameters['SEED'])\n",
    "\n",
    "# Sanity check\n",
    "n_classes = dls.c if n_tasks>1 else [dls.c] \n",
    "classes = dls.vocab if n_tasks>1 else [dls.vocab]\n",
    "print('Number of clases: ', n_classes)\n",
    "print('Names of classes: ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show batch\n",
    "dls.train.show_batch(max_n=16, figsize=(15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show transforms\n",
    "dls.train.show_batch(max_n=16, unique=True, figsize=(15,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = getattr(sys.modules[__name__], hyperparameters['LOSS_FUNC'])(weight=None)\n",
    "metrics = [accuracy, F1Score(average='macro')]\n",
    "callbacks = [SaveModelCallback(monitor='f1_score', with_opt=True), ShowGraphCallback]\n",
    "\n",
    "# Learner\n",
    "learn = vision_learner(dls,\n",
    "                        hyperparameters['ARCH'],\n",
    "                        normalize=True,\n",
    "                        pretrained=True,\n",
    "                        n_out=sum(n_classes),\n",
    "                        loss_func=loss,\n",
    "                        opt_func=getattr(sys.modules[__name__], hyperparameters['OPT_FUNC']),\n",
    "                        metrics=metrics,\n",
    "                        wd=hyperparameters['WD']).to_fp16()\n",
    "\n",
    "# Fix issue with pickling while calling learn.export\n",
    "import typing, functools\n",
    "learn.loss_func.func.__annotations__ = typing.get_type_hints(learn.loss_func.func, globalns=globals(), localns=locals())\n",
    "functools.update_wrapper(learn.loss_func, learn.loss_func.func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampled_epoch(self, class_weights = None):\n",
    "    item_weights = self.items.label.apply(lambda x: class_weights[str(x)])\n",
    "    oversampled_idxs = self.items.sample(n=self.n, weights=item_weights, replace=True).index\n",
    "    return [np.where(self.items.index == i)[0][0] for i in oversampled_idxs]\n",
    "\n",
    "# Oversampling\n",
    "if hyperparameters['USE_OVERSAMPLING']:\n",
    "    class_weights = pd.DataFrame(1 / np.sqrt(learn.dls.items.label.value_counts())).rename(index=lambda x: str(x)).to_dict()['count']\n",
    "    learn.dls.train.get_idxs = types.MethodType(partial(oversampled_epoch, class_weights=class_weights), learn.dls.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find LR\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set LR\n",
    "hyperparameters['LR'] = 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "learn.fine_tune(hyperparameters['EPOCHS'], base_lr=hyperparameters['LR'], cbs=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(ground_truths, predictions, classes, path, figsize=(16,16), num_size=12, order_by_classes=False):\n",
    "    '''\n",
    "    Creates and plots a confusion matrix given the ground truths and the predictions of the classification model.\n",
    "\n",
    "    Args:\n",
    "        ground_truths (torch.tensor): ground truth (correct) target values.\n",
    "        predictions (torch.tensor): estimated targets as returned by the model.\n",
    "        classes (list): list of the classes labels.\n",
    "\n",
    "    Returns:\n",
    "        fig (matplotlib.figure.Figure): figure object.\n",
    "    '''\n",
    "\n",
    "    labels = classes if order_by_classes else None\n",
    "    cm = confusion_matrix(ground_truths, predictions, labels=labels)\n",
    "    cm_norm = confusion_matrix(ground_truths, predictions, labels=labels, normalize='true')\n",
    "\n",
    "    df = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "    df_norm = pd.DataFrame(cm_norm, index=classes, columns=classes)\n",
    "\n",
    "    plt.figure(figsize = figsize)\n",
    "    ax = sns.heatmap(df_norm, annot=df, fmt='d', linewidths=0.5, linecolor='black', cmap='YlGn', vmin=0, vmax=1, annot_kws={\"color\": \"black\", \"size\": num_size})\n",
    "\n",
    "    for _, spine in ax.spines.items():\n",
    "        spine.set_visible(True)\n",
    "        spine.set_color('black')\n",
    "        spine.set_linewidth(2)\n",
    "\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.outline.set_edgecolor('black')\n",
    "    cbar.outline.set_linewidth(1.5)\n",
    "\n",
    "    ax.set_title('Confusion Matrix', fontdict={'fontsize': 32, 'fontweight': 'medium'})\n",
    "    ax.set_xlabel('Predicted class', fontsize=18)\n",
    "    ax.set_ylabel('True class', fontsize=18)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', fontsize=12)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, ha='right', fontsize=12)\n",
    "    fig = ax.get_figure()\n",
    "    plt.savefig(f'{path}confusion.png', bbox_inches='tight')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_losses(learn, path):\n",
    "    '''\n",
    "    Creates and plots a figure with the training and validation losses curves.\n",
    "\n",
    "    Args:\n",
    "        learn (fastai.learner.Learner): trained learner object.\n",
    "\n",
    "    Returns:\n",
    "        fig (matplotlib.figure.Figure): figure object.\n",
    "    '''\n",
    "\n",
    "    rec = learn.recorder\n",
    "    train_losses = np.array(rec.losses)\n",
    "    train_iters = np.linspace(0, learn.n_epoch, len(train_losses))\n",
    "    valid_losses = [v[1] for v in rec.values]\n",
    "    valid_iters = np.arange(1, learn.n_epoch+1)\n",
    "\n",
    "    plt.figure()\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plot = sns.lineplot(x=train_iters, y=train_losses, label='Train', linestyle='-')\n",
    "    sns.lineplot(x=valid_iters, y=valid_losses, label='Valid', marker='o', linestyle='--', color='green')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    fig = plot.figure\n",
    "    plt.savefig(f'{path}losses.png', bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_metrics(learn, path):\n",
    "    '''\n",
    "    Creates and plots a figure with the curves of all metrics.\n",
    "\n",
    "    Args:\n",
    "        learn (fastai.learner.Learner): trained learner object.\n",
    "\n",
    "    Returns:\n",
    "        fig (matplotlib.figure.Figure): figure object.\n",
    "    '''\n",
    "\n",
    "    valid_iters = np.arange(1, learn.n_epoch+1)\n",
    "    met = np.array([v[2:] for v in learn.recorder.values])\n",
    "    try:\n",
    "        metrics_names = [m.func.__name__ for m in learn.metrics]\n",
    "    except:\n",
    "        metrics_names = [m.__name__ for m in learn.metrics]\n",
    "\n",
    "    plt.figure()\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    for i in np.arange(len(metrics_names)):\n",
    "        plot = sns.lineplot(x=valid_iters, y=met[:,i], label=metrics_names[i], linestyle='-')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.legend()   \n",
    "    fig = plot.figure\n",
    "    plt.savefig(f'{path}metrics.png', bbox_inches='tight')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def get_predictions_table(learn, dl):\n",
    "    '''\n",
    "    Creates a table containing a row for each image stored in 'dl'.\n",
    "\n",
    "    Args:\n",
    "        learn (fastai.learner.Learner): trained learner object.\n",
    "        dl (fastai.data.core.TfmdDL): dataloader with the images for making predictions.\n",
    "\n",
    "    Returns:\n",
    "        df (pandas.core.frame.DataFrame): table with columns=['file_name', 'ground_truth', 'prediction', 'loss', 'confidence'], sorted by 'loss' value in descending order.\n",
    "    '''\n",
    "\n",
    "    labels = dl.vocab\n",
    "    file_paths = dl.dataset.items.file_path.values\n",
    "    probs, ground_truths, losses = learn.get_preds(dl=dl, with_loss=True)\n",
    "    predictions = np.argmax(probs, axis=1)\n",
    "    data = np.array([file_paths, np.array(labels[ground_truths]), np.array(labels[predictions]), np.array(losses), np.max(probs.numpy(),axis=1)]).T\n",
    "    table = pd.DataFrame(data=data, columns=[\"file_name\", \"ground_truth\", \"prediction\", \"loss\", \"confidence\"])\n",
    "    \n",
    "    return table.sort_values(by='loss', ascending=False)\n",
    "\n",
    "def get_metrics(learn):\n",
    "    '''\n",
    "    Returns a dictionary with the names and values of the metrics.\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        names = [m.func.__name__ for m in learn.metrics]\n",
    "    except:\n",
    "        names = [m.__name__ for m in learn.metrics]\n",
    "    values = learn.validate()[1:]        \n",
    "    metrics = dict(zip(names, values))\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill, itertools\n",
    "\n",
    "# Export model\n",
    "learn.export(f'{save_path}/model.pkl', pickle_module=dill)\n",
    "learn.save(f'{save_path}/model')\n",
    "\n",
    "# Plot losses and metrics across training\n",
    "_ = plot_losses(learn, save_path)\n",
    "_ = plot_metrics(learn, save_path)\n",
    "\n",
    "# Get confusion matrix\n",
    "probs, ground_truths = learn.get_preds(ds_idx=1)        # DO NOT PREDICT BEFORE PLOTTING LOSSES AND METRICS\n",
    "ground_truths = ground_truths if n_tasks>1 else [ground_truths]\n",
    "predictions = [np.argmax(probs[:,sum(n_classes[:i]):sum(n_classes[:i+1])], axis=1) for i in range(n_tasks)]\n",
    "decoded_preds = [' '.join([classes[i][p] for i, p in enumerate(tensor(g))]) for g in zip(*predictions)]\n",
    "decoded_gts = [' '.join([classes[i][p] for i, p in enumerate(tensor(g))]) for g in zip(*ground_truths)]\n",
    "new_vocab = [' '.join(i) for i in list(itertools.product(*classes))]\n",
    "_ = plot_confusion_matrix(decoded_gts, decoded_preds, new_vocab, save_path)\n",
    "\n",
    "# Get tables of predictions\n",
    "train_table = get_predictions_table(learn, learn.dls.train)\n",
    "valid_table = get_predictions_table(learn, learn.dls.valid)\n",
    "train_table.to_csv(f'{save_path}train_table.csv', index=False)\n",
    "valid_table.to_csv(f'{save_path}valid_table.csv', index=False)\n",
    "\n",
    "# Get final metrics\n",
    "results = get_metrics(learn)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multicare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
